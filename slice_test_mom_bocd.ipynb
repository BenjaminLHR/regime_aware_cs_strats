{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fca43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ec5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LTR_HDF_PATH = Path(\"features/ltr_df.h5\")\n",
    "LTR_HDF_KEY  = \"ltr_df\"\n",
    "ltr_df = pd.read_hdf(LTR_HDF_PATH, key=LTR_HDF_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df27b13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKTEST_H5 = \"D:/oxford/Dissertation/cs_strats/results/norm_by_lag/h5/bocd_clean/backtest_df_mlogloss_mom_bocd_exp_clean_mono_con_norm_by_lag_std.h5\"\n",
    "BACKTEST_KEY = 'backtest_df_mlogloss_mom_bocd_exp_clean_mono_con_norm_by_lag_std'\n",
    "\n",
    "BACKTEST_H5 = \"YOUR_BACKTEST_DF_PATH\"\n",
    "BACKTEST_KEY = 'YOUR_BACKTEST_KEY'\n",
    "\n",
    "backtest_df = pd.read_hdf(BACKTEST_H5, BACKTEST_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f9c44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['slow_mom_vtskip_252_42_z  x  Pr_le_63 (mature=low)', 'slow_mom_vtskip_252_42_z  x  Pr_le_252_z (mature=low)', 'slow_mom_vtskip_252_42_z  x  E_rt_z (mature=high)', 'slow_mom_vtskip_252_42_z  x  Var_rt_z (uncertainty)', 'macd_32_96_lag_3m_z  x  Pr_le_63 (mature=low)', 'slow_mom_vtskip_252_42_z  x  Pr_le_126_z (mature=low)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interaction</th>\n",
       "      <th>momentum_bin</th>\n",
       "      <th>other_bin</th>\n",
       "      <th>n_dates</th>\n",
       "      <th>n_obs_total</th>\n",
       "      <th>mean_s</th>\n",
       "      <th>se_mean_s</th>\n",
       "      <th>share_long</th>\n",
       "      <th>se_share_long</th>\n",
       "      <th>mean_p_top</th>\n",
       "      <th>se_mean_p_top</th>\n",
       "      <th>mean_p_bottom</th>\n",
       "      <th>se_mean_p_bottom</th>\n",
       "      <th>mean_y</th>\n",
       "      <th>se_mean_y</th>\n",
       "      <th>mean_target_pct</th>\n",
       "      <th>se_mean_target_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slow_mom_vtskip_252_42_z  x  Pr_le_126_z (matu...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>MATURE</td>\n",
       "      <td>5034</td>\n",
       "      <td>508849</td>\n",
       "      <td>-0.004312</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.476951</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.336309</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.340621</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.483564</td>\n",
       "      <td>0.043692</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0.001745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>slow_mom_vtskip_252_42_z  x  Pr_le_126_z (matu...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>YOUNG</td>\n",
       "      <td>4705</td>\n",
       "      <td>586828</td>\n",
       "      <td>-0.028341</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.280858</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.295146</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.323487</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.378330</td>\n",
       "      <td>0.033909</td>\n",
       "      <td>-0.020215</td>\n",
       "      <td>0.001584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>slow_mom_vtskip_252_42_z  x  Pr_le_126_z (matu...</td>\n",
       "      <td>POS</td>\n",
       "      <td>MATURE</td>\n",
       "      <td>5034</td>\n",
       "      <td>493857</td>\n",
       "      <td>-0.002396</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.509582</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>0.340030</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.342426</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.559283</td>\n",
       "      <td>0.042764</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>0.001798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slow_mom_vtskip_252_42_z  x  Pr_le_126_z (matu...</td>\n",
       "      <td>POS</td>\n",
       "      <td>YOUNG</td>\n",
       "      <td>4705</td>\n",
       "      <td>415878</td>\n",
       "      <td>0.005144</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.487301</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.324665</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.319522</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.493437</td>\n",
       "      <td>0.035699</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         interaction momentum_bin other_bin  \\\n",
       "0  slow_mom_vtskip_252_42_z  x  Pr_le_126_z (matu...          NEG    MATURE   \n",
       "1  slow_mom_vtskip_252_42_z  x  Pr_le_126_z (matu...          NEG     YOUNG   \n",
       "2  slow_mom_vtskip_252_42_z  x  Pr_le_126_z (matu...          POS    MATURE   \n",
       "3  slow_mom_vtskip_252_42_z  x  Pr_le_126_z (matu...          POS     YOUNG   \n",
       "\n",
       "   n_dates  n_obs_total    mean_s  se_mean_s  share_long  se_share_long  \\\n",
       "0     5034       508849 -0.004312   0.000308    0.476951       0.001788   \n",
       "1     4705       586828 -0.028341   0.000212    0.280858       0.001438   \n",
       "2     5034       493857 -0.002396   0.000323    0.509582       0.001866   \n",
       "3     4705       415878  0.005144   0.000222    0.487301       0.001824   \n",
       "\n",
       "   mean_p_top  se_mean_p_top  mean_p_bottom  se_mean_p_bottom    mean_y  \\\n",
       "0    0.336309       0.000222       0.340621          0.000134  0.483564   \n",
       "1    0.295146       0.000161       0.323487          0.000201  0.378330   \n",
       "2    0.340030       0.000148       0.342426          0.000231  0.559283   \n",
       "3    0.324665       0.000180       0.319522          0.000184  0.493437   \n",
       "\n",
       "   se_mean_y  mean_target_pct  se_mean_target_pct  \n",
       "0   0.043692         0.002168            0.001745  \n",
       "1   0.033909        -0.020215            0.001584  \n",
       "2   0.042764         0.012811            0.001798  \n",
       "3   0.035699         0.001543            0.001756  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_COL = \"fwd_ret_div_sigma_lag_63\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class InteractionSpec:\n",
    "    \"\"\"\n",
    "    Slice definition: a momentum feature and a second (state) feature.\n",
    "\n",
    "    Momentum is split at `ret_neg_threshold` into NEG/POS. The other feature\n",
    "    is binned into LOW/HIGH using the `low_q` and `high_q` quantiles; bin\n",
    "    names come from `low_label` and `high_label`.\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    momentum_feature: str\n",
    "    other_feature: str\n",
    "    low_q: float = 0.20\n",
    "    high_q: float = 0.80\n",
    "    low_label: str = \"MATURE\"\n",
    "    high_label: str = \"YOUNG\"\n",
    "    ret_neg_threshold: float = 0.0\n",
    "\n",
    "\n",
    "# Helpers\n",
    "def _slugify(text: str) -> str:\n",
    "    text = text.strip().lower()\n",
    "    text = re.sub(r\"[^a-z0-9]+\", \"-\", text)\n",
    "    text = re.sub(r\"-+\", \"-\", text).strip(\"-\")\n",
    "    return text or \"interaction\"\n",
    "\n",
    "\n",
    "def _share_long(x: pd.Series) -> float:\n",
    "    return float((x > 0.0).mean()) if len(x) else np.nan\n",
    "\n",
    "\n",
    "def _mean_and_se(x: pd.Series) -> Tuple[float, float]:\n",
    "    mu = float(x.mean())\n",
    "    se = float(x.std(ddof=1) / np.sqrt(len(x))) if len(x) > 1 else np.nan\n",
    "    return mu, se\n",
    "\n",
    "\n",
    "def _add_signed_percentile_by_date(\n",
    "    df: pd.DataFrame,\n",
    "    value_col: str,\n",
    "    date_col: str = \"date\",\n",
    "    new_col: str = \"target_pct_signed\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Per-date signed percentile in (-1, 1): 2 * (rank/(n+1)) - 1.\n",
    "    Robust to ties and comparable across dates.\n",
    "    \"\"\"\n",
    "    pct = df.groupby(date_col, observed=True)[value_col].rank(method=\"average\", pct=True)\n",
    "    n = df.groupby(date_col, observed=True)[value_col].transform(\"count\")\n",
    "    factor = n / (n + 1.0)\n",
    "    df[new_col] = 2.0 * pct * factor - 1.0\n",
    "    return df\n",
    "\n",
    "\n",
    "# Core functions\n",
    "def build_oos_master(\n",
    "    ltr_df: pd.DataFrame,\n",
    "    backtest_df: pd.DataFrame,\n",
    "    features: Iterable[str],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a minimal OOS frame (test rows only) with required columns.\n",
    "    Ensures `TARGET_COL` is present and adds a per-date signed percentile of it.\n",
    "    \"\"\"\n",
    "    cols_bt = [\"date\", \"permno\", \"p_bottom_test\", \"p_middle_test\", \"p_top_test\", \"net_score_test\"]\n",
    "    if TARGET_COL in backtest_df.columns:\n",
    "        cols_bt = cols_bt + [TARGET_COL]\n",
    "\n",
    "    for c in cols_bt:\n",
    "        if c not in backtest_df.columns:\n",
    "            raise KeyError(f\"Required column missing in backtest_df: {c}\")\n",
    "\n",
    "    keep_ltr = [\"date\", \"permno\"] + sorted(set(features))\n",
    "    if TARGET_COL not in backtest_df.columns:\n",
    "        keep_ltr = keep_ltr + [TARGET_COL]\n",
    "\n",
    "    for c in keep_ltr:\n",
    "        if c not in ltr_df.columns:\n",
    "            raise KeyError(f\"Required column missing in ltr_df: {c}\")\n",
    "\n",
    "    merged = (\n",
    "        ltr_df[keep_ltr]\n",
    "        .merge(backtest_df[cols_bt], on=[\"date\", \"permno\"], how=\"inner\", validate=\"one_to_one\")\n",
    "        .copy()\n",
    "    )\n",
    "    merged[\"date\"] = pd.to_datetime(merged[\"date\"])\n",
    "    if TARGET_COL not in merged.columns:\n",
    "        raise KeyError(f\"Could not find {TARGET_COL} after merge.\")\n",
    "\n",
    "    oos = merged.loc[merged[\"net_score_test\"].notna()].copy()\n",
    "    oos = _add_signed_percentile_by_date(oos, TARGET_COL, date_col=\"date\", new_col=\"target_pct_signed\")\n",
    "    return oos\n",
    "\n",
    "\n",
    "def run_single_interaction(\n",
    "    oos_master: pd.DataFrame,\n",
    "    spec: InteractionSpec,\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Run one interaction:\n",
    "      • bin by momentum (NEG/POS) and other feature (LOW/HIGH),\n",
    "      • compute date-balanced cell stats,\n",
    "      • compute paired diffs (HIGH − LOW) within NEG and POS.\n",
    "\n",
    "    Returns: thresholds, cell_summary, paired_diff_NEG, paired_diff_POS.\n",
    "    \"\"\"\n",
    "    needed = [\n",
    "        spec.momentum_feature,\n",
    "        spec.other_feature,\n",
    "        \"net_score_test\",\n",
    "        \"p_top_test\",\n",
    "        \"p_bottom_test\",\n",
    "        TARGET_COL,\n",
    "        \"target_pct_signed\",\n",
    "    ]\n",
    "    for c in needed:\n",
    "        if c not in oos_master.columns:\n",
    "            raise KeyError(f\"Column '{c}' not found in oos_master.\")\n",
    "\n",
    "    oos = oos_master.dropna(subset=[spec.momentum_feature, spec.other_feature]).copy()\n",
    "\n",
    "    # Quantile cuts for the other feature\n",
    "    low_cut = float(oos[spec.other_feature].quantile(spec.low_q))\n",
    "    high_cut = float(oos[spec.other_feature].quantile(spec.high_q))\n",
    "\n",
    "    # Define bins\n",
    "    oos[\"momentum_bin\"] = np.where(oos[spec.momentum_feature] < spec.ret_neg_threshold, \"NEG\", \"POS\")\n",
    "    oos[\"other_bin\"] = np.select(\n",
    "        [oos[spec.other_feature] <= low_cut, oos[spec.other_feature] >= high_cut],\n",
    "        [spec.low_label, spec.high_label],\n",
    "        default=\"MID\",\n",
    "    )\n",
    "    oos = oos.loc[oos[\"other_bin\"].isin([spec.low_label, spec.high_label])].copy()\n",
    "\n",
    "    # Per-date cell metrics (date-balanced)\n",
    "    per_date = (\n",
    "        oos.groupby([\"date\", \"momentum_bin\", \"other_bin\"], observed=True)\n",
    "        .agg(\n",
    "            n=(\"net_score_test\", \"size\"),\n",
    "            mean_s=(\"net_score_test\", \"mean\"),\n",
    "            share_long=(\"net_score_test\", _share_long),\n",
    "            mean_p_top=(\"p_top_test\", \"mean\"),\n",
    "            mean_p_bottom=(\"p_bottom_test\", \"mean\"),\n",
    "            mean_y=(TARGET_COL, \"mean\"),\n",
    "            mean_target_pct=(\"target_pct_signed\", \"mean\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Collapse across dates (each date gets equal weight)\n",
    "    summaries: List[Dict[str, float]] = []\n",
    "    for (mom, oth), g in per_date.groupby([\"momentum_bin\", \"other_bin\"], observed=True):\n",
    "        mu_s, se_s = _mean_and_se(g[\"mean_s\"])\n",
    "        mu_share, se_share = _mean_and_se(g[\"share_long\"])\n",
    "        mu_ptop, se_ptop = _mean_and_se(g[\"mean_p_top\"])\n",
    "        mu_pbot, se_pbot = _mean_and_se(g[\"mean_p_bottom\"])\n",
    "        mu_y, se_y = _mean_and_se(g[\"mean_y\"])\n",
    "        mu_pct, se_pct = _mean_and_se(g[\"mean_target_pct\"])\n",
    "        summaries.append(\n",
    "            {\n",
    "                \"interaction\": spec.name,\n",
    "                \"momentum_bin\": mom,\n",
    "                \"other_bin\": oth,\n",
    "                \"n_dates\": int(g[\"date\"].nunique()),\n",
    "                \"n_obs_total\": int(g[\"n\"].sum()),\n",
    "                \"mean_s\": mu_s,\n",
    "                \"se_mean_s\": se_s,\n",
    "                \"share_long\": mu_share,\n",
    "                \"se_share_long\": se_share,\n",
    "                \"mean_p_top\": mu_ptop,\n",
    "                \"se_mean_p_top\": se_ptop,\n",
    "                \"mean_p_bottom\": mu_pbot,\n",
    "                \"se_mean_p_bottom\": se_pbot,\n",
    "                \"mean_y\": mu_y,\n",
    "                \"se_mean_y\": se_y,\n",
    "                \"mean_target_pct\": mu_pct,\n",
    "                \"se_mean_target_pct\": se_pct,\n",
    "            }\n",
    "        )\n",
    "    cell_summary = pd.DataFrame(summaries).sort_values([\"momentum_bin\", \"other_bin\"])\n",
    "\n",
    "    # Paired HIGH − LOW diffs within each momentum side\n",
    "    def _paired_diff(df_in: pd.DataFrame, momentum_label: str) -> pd.DataFrame:\n",
    "        g = df_in.loc[df_in[\"momentum_bin\"] == momentum_label].copy()\n",
    "\n",
    "        # score\n",
    "        wide_s = g.pivot(index=\"date\", columns=\"other_bin\", values=\"mean_s\")\n",
    "        wide_s = wide_s.loc[wide_s[[spec.low_label, spec.high_label]].notna().all(axis=1)]\n",
    "        diff_s = wide_s[spec.high_label] - wide_s[spec.low_label]\n",
    "\n",
    "        # share_long\n",
    "        wide_share = g.pivot(index=\"date\", columns=\"other_bin\", values=\"share_long\")\n",
    "        wide_share = wide_share.loc[wide_share[[spec.low_label, spec.high_label]].notna().all(axis=1)]\n",
    "        diff_share = wide_share[spec.high_label] - wide_share[spec.low_label]\n",
    "\n",
    "        # realized target (raw)\n",
    "        wide_y = g.pivot(index=\"date\", columns=\"other_bin\", values=\"mean_y\")\n",
    "        wide_y = wide_y.loc[wide_y[[spec.low_label, spec.high_label]].notna().all(axis=1)]\n",
    "        diff_y = wide_y[spec.high_label] - wide_y[spec.low_label]\n",
    "\n",
    "        # realized target (signed percentile)\n",
    "        wide_pct = g.pivot(index=\"date\", columns=\"other_bin\", values=\"mean_target_pct\")\n",
    "        wide_pct = wide_pct.loc[wide_pct[[spec.low_label, spec.high_label]].notna().all(axis=1)]\n",
    "        diff_pct = wide_pct[spec.high_label] - wide_pct[spec.low_label]\n",
    "\n",
    "        n_dates = int(len(diff_s))\n",
    "        mu_diff_s, se_diff_s = _mean_and_se(diff_s) if n_dates else (np.nan, np.nan)\n",
    "        mu_diff_share, se_diff_share = _mean_and_se(diff_share) if n_dates else (np.nan, np.nan)\n",
    "        mu_diff_y, se_diff_y = _mean_and_se(diff_y) if n_dates else (np.nan, np.nan)\n",
    "        mu_diff_pct, se_diff_pct = _mean_and_se(diff_pct) if n_dates else (np.nan, np.nan)\n",
    "\n",
    "        return pd.DataFrame(\n",
    "            {\n",
    "                \"interaction\": [spec.name],\n",
    "                \"momentum_bin\": [momentum_label],\n",
    "                \"n_dates_paired\": [n_dates],\n",
    "                f\"mean_diff_s_{spec.high_label}_minus_{spec.low_label}\": [mu_diff_s],\n",
    "                \"se_diff_s\": [se_diff_s],\n",
    "                f\"mean_diff_share_long_{spec.high_label}_minus_{spec.low_label}\": [mu_diff_share],\n",
    "                \"se_diff_share_long\": [se_diff_share],\n",
    "                f\"mean_diff_y_{spec.high_label}_minus_{spec.low_label}\": [mu_diff_y],\n",
    "                \"se_diff_y\": [se_diff_y],\n",
    "                f\"mean_diff_target_pct_{spec.high_label}_minus_{spec.low_label}\": [mu_diff_pct],\n",
    "                \"se_diff_target_pct\": [se_diff_pct],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    paired_diff_neg = _paired_diff(per_date, \"NEG\")\n",
    "    paired_diff_pos = _paired_diff(per_date, \"POS\")\n",
    "\n",
    "    thresholds = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"interaction\": spec.name,\n",
    "                \"momentum_feature\": spec.momentum_feature,\n",
    "                \"other_feature\": spec.other_feature,\n",
    "                \"ret_neg_threshold\": spec.ret_neg_threshold,\n",
    "                \"low_q\": spec.low_q,\n",
    "                \"high_q\": spec.high_q,\n",
    "                \"low_cut_value\": low_cut,\n",
    "                \"high_cut_value\": high_cut,\n",
    "                \"low_label\": spec.low_label,\n",
    "                \"high_label\": spec.high_label,\n",
    "                \"target_col\": TARGET_COL,\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"thresholds\": thresholds,\n",
    "        \"cell_summary\": cell_summary,\n",
    "        \"paired_diff_NEG\": paired_diff_neg,\n",
    "        \"paired_diff_POS\": paired_diff_pos,\n",
    "    }\n",
    "\n",
    "\n",
    "def run_all_interactions(\n",
    "    ltr_df: pd.DataFrame,\n",
    "    backtest_df: pd.DataFrame,\n",
    "    interactions: List[InteractionSpec],\n",
    "    results_root: str = \"slice_results/mom_bocd\",\n",
    "    save: bool = True,\n",
    ") -> Dict[str, Dict[str, pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Run all specs and optionally write CSVs (fixed output folder, no timestamp).\n",
    "    Returns a nested dict: {interaction_name: {tables...}}.\n",
    "    \"\"\"\n",
    "    # Build once with the union of required features\n",
    "    feat_union = set()\n",
    "    for sp in interactions:\n",
    "        feat_union.add(sp.momentum_feature)\n",
    "        feat_union.add(sp.other_feature)\n",
    "    oos_master = build_oos_master(ltr_df, backtest_df, features=feat_union)\n",
    "\n",
    "    if save:\n",
    "        os.makedirs(results_root, exist_ok=True)\n",
    "\n",
    "    all_results: Dict[str, Dict[str, pd.DataFrame]] = {}\n",
    "    for sp in interactions:\n",
    "        res = run_single_interaction(oos_master, sp)\n",
    "        all_results[sp.name] = res\n",
    "\n",
    "        if save:\n",
    "            subdir = os.path.join(results_root, _slugify(sp.name))\n",
    "            os.makedirs(subdir, exist_ok=True)\n",
    "            res[\"thresholds\"].to_csv(os.path.join(subdir, \"thresholds.csv\"), index=False)\n",
    "            res[\"cell_summary\"].to_csv(os.path.join(subdir, \"cell_summary.csv\"), index=False)\n",
    "            res[\"paired_diff_NEG\"].to_csv(os.path.join(subdir, \"paired_diff_NEG.csv\"), index=False)\n",
    "            res[\"paired_diff_POS\"].to_csv(os.path.join(subdir, \"paired_diff_POS.csv\"), index=False)\n",
    "\n",
    "    # Combined rollups\n",
    "    if save and all_results:\n",
    "        thresholds_all = pd.concat([v[\"thresholds\"] for v in all_results.values()], ignore_index=True)\n",
    "        cell_all = pd.concat([v[\"cell_summary\"] for v in all_results.values()], ignore_index=True)\n",
    "        diffs_neg_all = pd.concat([v[\"paired_diff_NEG\"] for v in all_results.values()], ignore_index=True)\n",
    "        diffs_pos_all = pd.concat([v[\"paired_diff_POS\"] for v in all_results.values()], ignore_index=True)\n",
    "        thresholds_all.to_csv(os.path.join(results_root, \"ALL_thresholds.csv\"), index=False)\n",
    "        cell_all.to_csv(os.path.join(results_root, \"ALL_cell_summary.csv\"), index=False)\n",
    "        diffs_neg_all.to_csv(os.path.join(results_root, \"ALL_paired_diff_NEG.csv\"), index=False)\n",
    "        diffs_pos_all.to_csv(os.path.join(results_root, \"ALL_paired_diff_POS.csv\"), index=False)\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "# Default interaction set\n",
    "INTERACTIONS = [\n",
    "    InteractionSpec(\n",
    "        name=\"slow_mom_vtskip_252_42_z  x  Pr_le_63 (mature=low)\",\n",
    "        momentum_feature=\"(252, 42)_day_vol_time_scaled_ret_z\",\n",
    "        other_feature=\"Pr_le_63\",\n",
    "        low_q=0.20,\n",
    "        high_q=0.80,\n",
    "        low_label=\"MATURE\",\n",
    "        high_label=\"YOUNG\",\n",
    "    ),\n",
    "    InteractionSpec(\n",
    "        name=\"slow_mom_vtskip_252_42_z  x  Pr_le_252_z (mature=low)\",\n",
    "        momentum_feature=\"(252, 42)_day_vol_time_scaled_ret_z\",\n",
    "        other_feature=\"Pr_le_252_z\",\n",
    "        low_q=0.20,\n",
    "        high_q=0.80,\n",
    "        low_label=\"MATURE\",\n",
    "        high_label=\"YOUNG\",\n",
    "    ),\n",
    "    InteractionSpec(\n",
    "        name=\"slow_mom_vtskip_252_42_z  x  E_rt_z (mature=high)\",\n",
    "        momentum_feature=\"(252, 42)_day_vol_time_scaled_ret_z\",\n",
    "        other_feature=\"E_rt_z\",\n",
    "        low_q=0.20,\n",
    "        high_q=0.80,\n",
    "        low_label=\"YOUNG\",   # here HIGH means mature\n",
    "        high_label=\"MATURE\",\n",
    "    ),\n",
    "    InteractionSpec(\n",
    "        name=\"slow_mom_vtskip_252_42_z  x  Var_rt_z (uncertainty)\",\n",
    "        momentum_feature=\"(252, 42)_day_vol_time_scaled_ret_z\",\n",
    "        other_feature=\"Var_rt_z\",\n",
    "        low_q=0.20,\n",
    "        high_q=0.80,\n",
    "        low_label=\"LOW_VAR\",\n",
    "        high_label=\"HIGH_VAR\",\n",
    "    ),\n",
    "    InteractionSpec(\n",
    "        name=\"macd_32_96_lag_3m_z  x  Pr_le_63 (mature=low)\",\n",
    "        momentum_feature=\"32_96_lag_3m_z\",\n",
    "        other_feature=\"Pr_le_63\",\n",
    "        low_q=0.20,\n",
    "        high_q=0.80,\n",
    "        low_label=\"MATURE\",\n",
    "        high_label=\"YOUNG\",\n",
    "    ),\n",
    "    InteractionSpec(\n",
    "        name=\"slow_mom_vtskip_252_42_z  x  Pr_le_126_z (mature=low)\",\n",
    "        momentum_feature=\"(252, 42)_day_vol_time_scaled_ret_z\",\n",
    "        other_feature=\"Pr_le_126_z\",\n",
    "        low_q=0.20,\n",
    "        high_q=0.80,\n",
    "        low_label=\"MATURE\",\n",
    "        high_label=\"YOUNG\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "results = run_all_interactions(\n",
    "    ltr_df,\n",
    "    backtest_df,\n",
    "    INTERACTIONS,\n",
    "    results_root=\"slice_results/mom_bocd\",\n",
    "    save=True,\n",
    ")\n",
    "print(list(results.keys()))\n",
    "results[\"slow_mom_vtskip_252_42_z  x  Pr_le_126_z (mature=low)\"][\"cell_summary\"].head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ox311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
